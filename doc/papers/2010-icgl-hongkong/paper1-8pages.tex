% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode
% File acl-ijcnlp2009.tex
%
% Contact  jshin@csie.ncnu.edu.tw
%%
%% Based on the style files for EACL-2009 and IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl-ijcnlp2009}
\usepackage[	
   pdfdisplaydoctitle, breaklinks, colorlinks, linkcolor=black, citecolor=black, filecolor=black, urlcolor=black, 
   backref, hyperfootnotes]{hyperref} % backref a modre URL asi nakonec zrusime 
%\usepackage{times}
\usepackage{url}
\usepackage{amsmath}
\usepackage{listings} % zdrojáky programů
\usepackage{color} %pro korektury
\usepackage{paralist} % for better itemize and enumerate

% a footer required for the first page (ICON but not ICGL)
\usepackage{fancyhdr}
\fancyhead{} % clear all header fields
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[C]{
%Proceedings of ICON-2009: 7th International Conference on Natural Language Processing, Macmillan Publishers, India. Also accessible from http://ltrc.iiit.ac.in/proceedings/ICON-2009
}

% xelatex
\usepackage{fontspec, xunicode, xltxtra}
\defaultfontfeatures{Mapping=tex-text}
\setmainfont{Times New Roman}
\setmonofont[Scale=MatchLowercase]{Luxi Mono}
\setmathsf{Lohit Hindi}%\XXX
%\newfontinstance\hi[Script=Devanagari]{Lohit Hindi}
\newfontinstance\arfont[Script=Arabic]{Code2000}
\newfontinstance\hifont[Script=Devanagari]{Code2000}
\newfontinstance\bnfont[Script=Bengali]{Code2000}
\newfontinstance\tefont[Script=Telugu]{Code2000}
\newfontinstance\zhfont{Code2000}
\newfontinstance\translitfont{Gentium}
\newcommand{\ar}[1]{{\arfont #1}}
\newcommand{\hi}[1]{{\hifont #1}}
\newcommand{\bn}[1]{{\bnfont #1}}
\newcommand{\te}[1]{{\tefont #1}}
\newcommand{\zh}[1]{{\zhfont #1}}
\newcommand{\translit}[1]{{\translitfont \textit{(#1)}}}

% natbib
\usepackage{natbib}
\bibliographystyle{plainnat}
\bibpunct{(}{)}{;}{a}{,}{,}

% our defs
\def\perscite#1{\citet{#1}}  
\def\parcite#1{\citep{#1}} 
%ps: Did you mean \citep and \citet (in-parentheses and textual reference)? There is even more, see `texdoc natbib`.
\def\Sref#1{Section~\ref{#1}}
\def\Tref#1{Table~\ref{#1}}
\def\Fref#1{Figure~\ref{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}} % komentare (TODO)
\newcommand{\XXX}{\textcolor{red}{XXX }} % komentare (TODO)

\def\microsection#1{{\bf #1.}}



\title{Hard Problems of Tagset Conversion%
% Tohle nechat zakomentované, je to jen tahák, jak udělat acknowledgement grantu při nedostatku místa. Jinak ale mám momentálně na konci opravdovou sekci Acknowledgements.
%\thanks{ \hspace{.6em}The research has been supported by the grant 
%MSM0021620838 (Czech Ministry of Education).}
}

% Až to přestane být anonymní, tak také odkomentovat Acknowledgements a autoreference XXXX.
\author{%Daniel Zeman\\
%Univerzita Karlova v Praze, Ústav formální a aplikované lingvistiky\\
%Malostranské náměstí 25, CZ-11800, Praha, Czechia\\ 
%\texttt{zeman@ufal.mff.cuni.cz}
}

%\title{Instructions for ACL-IJCNLP 2009 Proceedings}
%
%\author{First Author\\
%  Affiliation / Address line 1\\
%  Affiliation / Address line 2\\
%  {\tt email@domain}  \And
%  Second Author\\
%  Affiliation / Address line 1\\
%  Affiliation / Address line 2\\
%  {\tt  email@domain}}

\date{}

\begin{document}
\maketitle
\thispagestyle{fancy}
\lstset{language=Perl}
\lstset{basicstyle=\ttfamily} % Pro zdrojový kód použít stejný font, jaký používám všude v \texttt{}.

\begin{abstract}
Part-of-speech or morphological tags are important means of annotation in a vast number of corpora. However, different sets of tags are used in different corpora, even for the same language. Tagset conversion is difficult, and solutions tend to be tailored to a particular pair of tagsets. We discuss Interset, a universal approach that makes the conversion tools reusable. While some morphosyntactic categories are clearly defined and easily ported from one tagset to another, there are also phenomena that are difficult to deal with because of overlapping concepts. In the present paper we focus on some of such problems, discuss their coverage in selected tagsets and propose solutions to unify the respective tagsets' approaches.
\end{abstract}

\section{Introduction}
\label{sec:intro}

Most annotated corpora use various types of tags to encode additional information on words. In some cases this information is merely the part of speech (“noun”, “verb” etc.—hence the term \textit{part-of-speech} or \textit{POS tags}). In many cases, however, the string of characters comprising the tag is a compressed representation of a feature-value structure. Most of the features encoded this way are morphosyntactic (e.g. “gender = masculine”, “number = singular”), hence the term \textit{morphological tags}.

Unfortunately, it is very rare to see two corpora sharing a common set of tags. Language differences are only partially responsible—it is the corpus designers, their diverse views, theories and intended uses of the corpora, what matters most. Even two corpora of the same language may define two completely incompatible tagsets.

Such diversity proves disadvantageous for both human users and NLP software. A human user (linguist) typically wants to submit queries such as “show me all occurrences of a noun in plural, preceded by a preposition”. Tags however rarely contain statements like “number = plural” literally. That would be prohibitively space-consuming. Instead we have to know that e.g. the fourth character of the tag being “P” means “plural”. For instance, the tag \texttt{NNIS7-{}-{}-{}-{}-A-{}-{}-{}-}\footnote{This example is taken from the Prague Dependency Treebank \citep{pdt}.} may read as “part of speech = noun, detailed part of speech = common noun, gender = masculine inanimate, number = singular, case = 7th (instrumental), negativeness = affirmative”. To work with the corpus efficiently, a linguist either needs to interpret the tags using specialized software, or to memorize the particular tag scheme. Obviously, if the same linguist has to switch to a different corpus, he/she must memorize more schemes or replace the tag interpretation software.

Similarly, various NLP tools may depend on particular tagsets. While some tools indeed treat tags as atomic strings, others could exploit the tag structure to dig more information about the word—no matter whether they use the features in machine learning, or in human-designed rules. If the tagset changes, manual rules become useless and statistical models have to be retrained at least; even that may not be possible in case the training procedure works with selected subsets of the feature pool. Applicability of NLP software to multiple corpora is exactly the reason why one would want to convert tags from one tagset to another.

For many tagset pairs, designing the conversion procedure is not easy. On one hand, there are rare tagsets (e.g. MULTEXT-EAST, \citet{multext-east}) fitting at the same time languages as distant as Czech and Estonian; on the other hand, tagsets of two closely related languages (e.g. Danish and Swedish) or even two tagsets of the same language may differ substantially (for instance, the Mamba tagset of Swedish \citep{talbanken} contains detailed classification of auxiliary verbs and punctuation but lacks features like number, mood, tense etc.; this is in sharp contrast to another Swedish tagset, Parole \citep{parolesv}, which in turn is not compatible with the Danish Parole \citep{paroleda} tagset (the former classifies participles as verb forms, the latter as adjective forms; the former has separate tags for numerals, the latter classifies both cardinal and ordinal numbers as adjectives; etc.)

From the above said it follows that the typical tag conversion is an information-losing process. Though it is often desirable to perform it anyway and preserve as much information as possible. Creation of a conversion procedure between two tagsets requires hours of tedious work, consisting mostly of reading the tagging guidelines and translating them into a programming language. A universal description, to which all tagsets map, could make this process easier, and its results reusable. One attempt to find such description and deploy it in the conversion task is DZ Interset \citep{biblio:ZeReusableTagset2008}. In the present paper we discuss the development of the universal description and focus on selected hard problems that arise when comparing various existing tagsets.

The rest of the paper is organized as follows: In \Sref{sec:interset} we describe Interset and how it works. In \Sref{sec:features} we describe our universal set of features. \Sref{sec:drivers} gives some implementation details of Interset-based conversion. Then, \Sref{sec:hard} lists decisions that are difficult w.r.t. universality, demonstrates them on real tagsets, and proposes solutions.

\section{Interset}
\label{sec:interset}

Interset is a universal set of features and their values. It shall be able to store all features that are usually encoded in tags. The role of this universal set is similar to the role of Interlingua in Interlingua-based machine translation \citep{interlingua} or the role of Unicode among character sets. The Interset serves as an intermediate step on the way from tagset A to tagset B. The interaction between the Interset and tagsets A and B, respectively, is described in \textit{tagset drivers}. Once the drivers have been implemented, we can do the two-way conversion A to B and B to A, plus the conversion between one of these tagsets and any other tagset that has been defined so far.

% Tenhle odstavec se případně může vypustit.
We are not likely to spare much effort during the initial phase, if compared to just writing a targeted A-to-B conversion procedure. Actually, covering two completely new tagsets requires more work and care: we should describe both encoding and decoding of each tagset, we may have to think about features that are present in neither of them, and we will probably want to be more careful about aspects that may not matter to our current application. However, the reusability of the resulting code should compensate for the effort more than adequately; it is even possible that the required tagset has been covered by someone else who is sharing the code on the web.

Besides abstract concept definitions, Interset also comprises some real software---supporting procedures that make adding new tagsets easier. Thanks to the encoding algorithm implemented in the support library, developers adding new tagsets need not (not necessarily) consider all features that are irrelevant to the tagset being added (but which may become relevant during conversion to a particular other tagset).

\subsection{A New Standard?}
\label{sec:notastandard}

\textbf{Interset is not a new annotation standard.} There have been attempts to standardize morphosyntactic tagging and it is not Interset's mission to compete with them. Instead, the goal is to cover as many existing tagsets as possible whether they conform to a standard or not. The set of Interset features and values could of course be compared to those defined in standards. There have been several European projects concerning tagset standardization. The EAGLES project \citep{eagles, LeechWilson1999} produced a set of recommendations for tagsets. Output of the LE-PAROLE project \citep{parole} was a multilingual corpus of 14 European languages, morphosyntactically annotated according to a common core PAROLE tagset, extended with a set of language specific features. Another multilingual corpus with common tagset is MULTEXT \citep{multext} for six European languages (English, French, Spanish, German, Italian and Dutch), and later its spin-off MULTEXT-EAST \citep{multext-east} for 12 languages (English, Bulgarian, Czech, Estonian, Hungarian, Romanian, Slovene, and in later versions also Croatian, Lithuanian, Resian, Russian and Serbian); the tagsets used in MULTEXT corpora comply with EAGLES. Various EAGLES-compliant tagsets can be added to our system and their mutual similarity will probably make adding them all easier. Weakly related is also the Gold Ontology project \citep{gold-ontology} that defines various linguistic concepts, some of which serve as feature names and feature values in Interset. Similarly, morphosyntactic and other terms are included in IsoCat.\footnote{\url{http://www.isocat.org/}}

Interset has been used in cross-language parser adaptation \citep{ZemanResnik2008}, and in MorphCon, a GUI program that brings tag conversion to corpus users \citep{morphcon}. Currently, it is being deployed as a means of unified access to morphosyntactic annotation for the users of the parallel multilingual corpus Intercorp.\footnote{\url{http://www.korpus.cz/intercorp/?req=doc:uvod}}

\subsection{A New Tagset?}
\label{sec:notatagset}

\textbf{Interset is not primarily meant as a new \textit{physical} tagset for annotation.} Although it obviously could be used that way (possibly after compressing the feature values), it is better thought of as a set of concepts that physical tagsets map to. Design of physical tagsets is often guided by various needs such as conforming to linguistic tradition and terminology of the given language, minimizing errors of automatic disambiguation etc. In contrast, the most important design constraint for Interset is the portability of information from one tagset to the others. If a feature value X, encoded in tagset A, is not available in tagset B but it is still probable that users of tagset B would tag the same set of words with feature value Y, then it is desirable that the Interset algorithms are able to change X to Y, when converting from A to B. At the same time, converting to tagset C might require changing X to Z, converting to tagset D would keep X (because D has X, too) and converting to other tagsets would result in resetting X to empty value because there is no better choice available.

Conversion via Interset often looses information but never adds new information. Interset may define feature value X but it just won't be set unless the source tagset defines it, too. Specifically, the conversion procedure does not retag words. For instance, the source tagset may define one tag \texttt{IN} for both prepositions and subordinating conjunctions. The target tagset may have separate tags for each of those categories. Will then Interset sort out the words tagged \texttt{IN} into prepositions and conjunctions? No! In fact, the procedure \textit{never} looks at the word the tag is assigned to. It only works with the tag itself.

\subsection{Features}
\label{sec:features}

The current version of Interset defines the following features and values. Besides the values listed, every feature is also allowed to have an empty value.

\begin{compactitem}
\item \texttt{\textbf{pos} = noun|adj|num|verb|adv|prep| conj|part|int|punc}
\item \texttt{\textbf{subpos} = prop|class|pdt|det|art|aux| cop|mod|ex|voc|post|circ|preppron| comprep|coor|sub|comp|emp|res|inf|vbp}
\item \texttt{\textbf{prontype} = prs|rcp|int|rel|dem|neg| ind|tot}
\item \texttt{\textbf{numtype} = card|ord|mult|frac|gen}
\item \texttt{\textbf{numform} = word|digit|roman}
\item \texttt{\textbf{numvalue} = 1|2|3}
\item \texttt{\textbf{advtype} = man|loc|tim|deg|cau}
\item \texttt{\textbf{punctype} = peri|qest|excl|quot|brck| comm|colo|semi|dash|symb|root}
\item \texttt{\textbf{puncside} = ini|fin}
\item \texttt{\textbf{synpos} = subst|attr|adv|pred}
\item \texttt{\textbf{poss} = poss}
\item \texttt{\textbf{reflex} = reflex}
\item \texttt{\textbf{negativeness} = pos|neg}
\item \texttt{\textbf{definiteness} = ind|def|red}
\item \texttt{\textbf{foreign} = foreign}
\item \texttt{\textbf{gender} = masc|fem|com|neut}
\item \texttt{\textbf{possgender} = masc|fem|com|neut}
\item \texttt{\textbf{animateness} = anim|nhum|inan}
\item \texttt{\textbf{number} = sing|dual|plu}
\item \texttt{\textbf{case} = nom|gen|dat|acc|voc|loc|ins| ill|ine|ela|all|ade|abl|par|tmp|ter| tra|ess|abe|com|cau|dis}
\item \texttt{\textbf{prepcase} = npr|pre}
\item \texttt{\textbf{degree} = pos|comp|sub|abs}
\item \texttt{\textbf{person} = 1|2|3}
\item \texttt{\textbf{politeness} = inf|pol}
\item \texttt{\textbf{subcat} = intr|tran}
\item \texttt{\textbf{verbform} = fin|inf|sup|part|trans| ger}
\item \texttt{\textbf{mood} = ind|imp|cnd|sub|jus}
\item \texttt{\textbf{tense} = past|pres|fut}
\item \texttt{\textbf{subtense} = aor|imp|pqp}
\item \texttt{\textbf{aspect} = imp|perf}
\item \texttt{\textbf{voice} = act|pass}
\item \texttt{\textbf{abbr} = abbr}
\item \texttt{\textbf{hyph} = hyph}
\item \texttt{\textbf{style} = arch|form|norm|coll}
\item \texttt{\textbf{typo} = typo}
\item \texttt{\textbf{variant} = short|long|0|1|2|3|4|5|6| 7|8|9}
\item \texttt{\textbf{other} = }\textit{any other info}
\item \texttt{\textbf{tagset} = }\textit{where does the other info come from?}
\end{compactitem}

The \texttt{other} feature can store arbitrary information that did not fit elsewhere. Typically, that sort of information is unique to the given tagset (not just unique to the language!), and goes too far from what tagsets usually encode. We do not believe that there will ever be another tagset encoding such information---if we did, we would update Interset to provide corresponding feature/value. However, it still makes sense to store the information so that a tagset can be converted to itself and no information is lost. Since the value of \texttt{other} is not understood by any other tagset, we need to know which tagset the value comes from. Thus the identifier of the tagset should be stored in the \texttt{tagset} feature.

%\XXX Tenhle odstavec asi vyhodit.
While several feature-based tagsets distinguish between unknown values and irrelevant features, we do not find it wise in Interset. For instance, the fifth character in the PDT Czech tagset identifies grammatical case. Its normal values are 1 to 7. For parts of speech that do not have case (e.g. interjections) the fifth character is \texttt{-} (dash). Adjectives generally do have case, yet there are borrowed words without Czech case suffixes whose case value is unknown (\texttt{X}). An example is the tag \texttt{AAIPX-{}-{}-{}-1A-{}-{}-{}-} for “Buenos” in Buenos Aires. The benefit of making this distinction explicit in a tagset is unclear. What is clear, however, is that we must not reflect it in the universal feature set. Who can say that a feature will be irrelevant—given the context of the values of the other features—in any tagset whatsoever? It is quite easy to find features that are relevant in one tagset and not the other: e.g. Czech past participles distinguish gender, English don’t.

\section{Tagset Drivers}
\label{sec:drivers}

While the Interset is merely an abstract definition, the real implementation lies in the tagset drivers. A driver is a code library responsible for decoding and encoding tags. Decoding is reading a string (tag) into an internal data structure, in accordance with the list of possible features and their values. Encoding works the other way around.

The encoder obviously is the more difficult part. The decoder just reads and sorts the information, ideally not losing a single piece of it. If anything has to be discarded because it does not fit the target tagset, the discarding is encoder’s task. There are two main reasons why encoding is not easy:

\begin{compactitem}
\item The encoder should be prepared to all values of all features, regardless that some of them are unknown in the particular tagset. For instance, if number = dual and the tagset does not know dual, it is probably better to encode plural than just leave number unknown.
\item Even if the target tagset knows features A and B, concrete value of A can restrict permitted values of B. Some combinations of feature values are not allowed. For instance, the Swedish Parole tagset allows “pos = noun \& gender = common | neuter”, and also “pos = pronoun \& gender = masculine | feminine | common | neuter”. If we are to encode “pos = noun \& gender = masculine”, we can either honor the part of speech, or the gender, but not both.
\end{compactitem}

Fortunately enough, unknown feature values / combinations can be dealt with automatically if the driver has the list of all possible tags. By decoding all tags on the list, we get feature values for every tag. We thus know all feature values permitted in the given tagset and we know all value combinations. We have defined an ordered list of back-off values for every Interset feature value. The back-off lists contain all other values of the feature, including the empty value, so it is guaranteed that we always find a value that is permitted.\footnote{The necessary condition is that the decoder only sets known feature values, which is desirable anyway.} Of course, the encoder can override the default back-off list if necessary.

As for unknown feature combinations, there is a predefined total ordering of the features that defines their priority (this can be overridden, too). Since features are ordered, all value combinations can be stored in a trie structure. On selecting value of a higher-priority feature, the structure immediately reveals restricted value space for all lower-priority features.

This back-off technique is implemented in a helper module. Any driver can call it and have the features adjusted to something the driver itself might produce during decoding. The encoder can then concentrate on the driver’s native feature combinations. Besides that, the helper module can also check a driver’s integrity by looking whether the decoder only sets known features and values, whether encode(decode(x)) = x etc.

The whole thing is implemented in Perl. The drivers are Perl modules whose encode and decode functions can be called from other Perl programs, either to access the feature values, or to convert tagsets. The conversion script is very simple and looks like this:\footnote{Real conversion script would also have to deal with the format in which the tags are mixed with text in the corpus. This example merely assumes a list of tags, without the actual words and other annotation.}

\begin{lstlisting}
use tagset::cs::pdt;
use tagset::en::penn;
while(<>)
{
    print tagset::en::penn::encode
        tagset::cs::pdt::decode $_, "\n";
}
\end{lstlisting}

At the time of writing there are drivers for 20 tagsets of 10 languages (Arabic, Bulgarian, Chinese, Czech, Danish, English, German, Polish, Portuguese and Swedish). Those drivers are freely available on the web.\footnote{\url{http://xxxxx.xx/}}
We believe that the reusability will only be truly exploited if the drivers are shared in the community and we encourage everyone to contribute with drivers they need to write for themselves.

\section{The Hard Problems}
\label{sec:hard}

Working with various tagsets, we identified several fields that were difficult to capture and unify.

%\XXX Pokud zbude místo, tak taky ukázat tu čínskou sadu značek a proč jsme z ní dokázali převzít pouze zlomek informace.

\subsection{Pronouns, Determiners, Articles and Wh-Adverbs}
\label{sec:pronouns}

Most languages and tagsets have personal pronouns, i.e. words like ``I'', ``you'', ``he'', ``she'', ``it''. Various interrogative and relative function words (wh-words in English) are often also considered pronouns. In addition, grammars of some languages distinguish \textit{determiners} while others prefer to categorize the same thing as a sort of pronouns. According to the definition of EAGLES, \textbf{pronoun} is a function word that \textit{replaces} a noun phrase, while \textbf{determiner} is a function word that \textit{modifies} a noun phrase. As a result, proper EAGLES-pronouns behave like nouns and determiners behave like adjectives. Note that possessive pronouns (i.e. ``my'', ``your'', ``his'', ``her'', ``its''), also found in many languages, are personal possessive determiners in the sense of the EAGLES definition.

% Následující odstavec by se dal doplnit z wiki a podobný by se dal z wiki přepsat i pro číslovky. Když ale jenom odkomentuju tenhle kus bez doplňování, tak zcela naplním 8 stran, a to jsou momentálně prázdné Acknowledgements. Takže po odanonymizování by to referencema přeteklo na 9. stranu, což je sice povoleno, ale jen malinko, což by nebylo hezké. Tak snad raději teď půjdu spát a počkám, jestli to vůbec přijmou a nebudou to chtít třeba zkrátit na poster. Abych teď pracně nepřidal něco, co pak stejně budu muset vyhodit.

%\XXX In the BulTreeBank \citep{bultreebank}, anything interrogative is a pronoun, although it could be considered numeral \textit{(how much?)} or adverb \textit{(where? when? how?)} elsewhere. Some tagsets address the variable syntactic behavior of pronouns (\textit{he} substitutes a noun, \textit{his} functions as an adjective). Some tagsets and languages do not have determiners but they have pronouns (demonstrative, indefinite) instead. All that lead us to remove pronouns and determiners as independent parts of speech. Instead, nouns, adjectives and adverbs have the feature “prontype” to distinguish the various types (personal, demonstrative, interrogative…) Empty value of this feature signals a normal noun (adjective, adverb).

Because tagsets often disagree in what is pronoun, what is determiner etc., it is difficult to find a unifying approach. We decided to limit the number of the major parts of speech in order to minimize the cases where a word would end up with an empty part of speech. If there were a part of speech called \textit{determiner}, drivers of tagsets not having determiners would either have to check whether \texttt{\textbf{pos} = det} during encoding, or they would fall back into a residual word class. On the other hand, if we tag determiners as special cases of adjectives (which is what Interset does), such drivers will simply encode determiners as adjectives (provided they have adjectives—but these are much more common).

We also followed this solution with pronouns because of the following reasons:
\begin{compactitem}
\item Although pronouns are found in most tagsets, there is much controversy about the precise extent of that category.
\item Some tagsets allow for distinguishing between \textit{substantive} and \textit{attributive} pronouns (roughly those that behave like nouns and those that behave like adjectives). Assigning pronouns to nouns and adjectives respectively helps preserve that distinction.
\item Some of the features that distinguish pronouns from real nouns and adjectives (interrogativeness, for instance) are found with adverbs and numerals as well and thus it makes sense to separate them.
\end{compactitem}

Pronouns are recognized by nonempty value of the \texttt{prontype} feature; default type is \texttt{prs}, which denotes personal pronouns under nouns, and possessive pronouns under adjectives. The drawback of this approach is that the encoding procedure of a driver that recognizes pronouns must define its own method of asking the question \textit{``Does the current feature-value structure correspond to a pronoun?''}

\subsection{Numerals}
\label{sec:numerals}

Numerals form an analogy to the pronoun-determiner problem. Most tagsets recognize cardinal numbers as a separate category. However, the rest is less obvious. Some tagsets recognize ordinal numbers while others classify them as adjectives because of their syntactic behavior. An extreme case is the Danish Parole tagset where all numbers including cardinals are adjectives; however, they form a distinguished subclass of adjectives and can thus be recognized. Tagsets of Czech and other Slavic languages define complex systems of numerals, according to traditional local grammars: besides cardinals and ordinals, there are separate tags for fractions (``one fifth''), multiplications (``five times''),\footnote{Note that in these languages such numerals can be expressed in one token, which justifies devising a tag for them.} adverbial ordinals (``for the first time''), various types of generic ordinals (``twofold'', ``four kinds of''), interrogative or relative numerals (``how many'', ``what'',\footnote{Here, the expected answer is ``first'', ``second'' etc. The ``what'' corresponds to different Slavic word than in e.g. ``What do you do for living?'' An example from Czech is \textit{kolikátý}.} ``how many times''), demonstrative numerals (``that many'', ``that many times''), indefinite numerals (``few'', ``much'') etc.

For the sake of consistency, the solution for numerals should be parallel to that of pronouns. Cardinal numbers, as the most specific and most widely recognized category, should retain their independence. The rest will be split among nouns (fractions), adjectives (ordinals and some generics) and adverbs (multiplications and ordinal points in time). Non-empty \texttt{numtype} feature will distinguish them from real nouns, adjectives and adverbs. Parallelly, \texttt{prontype} could be set, too, for interrogative, demonstrative and indefinite numerals.

%\subsection{Counted Nouns in Slavic Languages}
%\XXX Co s počítanými podstatnými jmény ve slovanských jazycích? To je ještě samostatný problém.

\subsection{Non-Finite Verb Forms}
\label{sec:participles}

Non-finite verb forms often constitute mixed categories from the syntactic point of view. The syntactic properties of participles overlap with adjectives. Similarly, gerunds resemble nouns and transgressives function as adverbs. At the same time however, they retain their verbal arguments.

Usually, these words are tagged as forms of verbs. However, there are exceptions. In the Swedish Parole tagset, participles are tagged as adjectives. Czech equivalent of gerunds is considered a deverbative noun; Czech participles have long and short forms, the former being tagged as adjectives, the latter as verbs. Some tagsets could even delimit participles as a separate part of speech, without clearly marking their affinity to adjectives or verbs. The Interset guidelines prefer marking all three categories (participles, gerunds and transgressives) as verbs.
Note however that any guidelines are only to ensure unified approach to different presentations of the same information. It does not apply to information that simply is not there. If participles were tagged as \textit{normal} adjectives without sub-dividing adjectives into ``normal ones'' and participles, they would remain so in Interset and also in the target tagset.

\subsection{Particles and Other Minor Parts of Speech}
\label{sec:particles}

Every tagset contains a number of specialized tags for small groups of words. They encode endemic phenomena that do not occur in other corpora/languages or simply are not distinguished there (because they are covered by other, broader-scope tags). Sometimes such tags are grouped as \textit{particles} or various ``residual'' classes. The approach of Interset is to roof them with some more common parts of speech, instead of introducing a new high-level class. We wanted to reduce the necessity of encoders’ taking care of parts of speech unknown in their home tagsets. Roofed word classes are usually distinguishable by one of the detailed-part-of-speech features.

An overview of various sorts of particles follows:

\begin{compactitem}
\item unclassified particle (Czech \texttt{TT}, English \texttt{RP}, Swedish \texttt{Q})
\item interrogative particle (Arabic \texttt{FI} \ar{هل} \translit{hal}, Bulgarian \texttt{Tn} \textit{ли} \translit{li})
\item affirmative particle (Bulgarian \texttt{Ta} \textit{да} \translit{da})
\item negative particle (Arabic \texttt{FN} \ar{لا} \translit{lā}, Bulgarian \texttt{Tn} \textit{не} \translit{ne}, German \texttt{PTKNEG} \textit{nicht})
\item response particle (German \texttt{PTKANT} \textit{ja} = “yes”, \textit{nein} = “no”, \textit{doch} = “yes”, \textit{danke} = “thank you”…)
\item auxiliary particle (Bulgarian \texttt{Tx} \textit{да} \translit{da} = “to”, \textit{ще} \translit{šte} = “will”)
\item modal particle (Bulgarian \texttt{Tm} \textit{май} \translit{maj} = “possibly”)
\item verbal particle (Bulgarian \texttt{Tv} \textit{нека} \translit{neka} = “let”)
\item emphasis particle (Bulgarian \texttt{Te} \textit{даже} \translit{daže} = “even”)
\item gradable particle (Bulgarian \texttt{Tg} \textit{най} \translit{naj} = “most”)
\item unique POS (Danish \texttt{U}, covering the words \textit{at} = infinitival “to”, \textit{som}, \textit{der})
\item infinitive mark (German \texttt{PTKZU} \textit{zu}, Swedish \texttt{IM} \textit{att}, English \texttt{TO} \textit{to} – includes prepositional occurrences of \textit{to})
\item separated verbal prefix (German \texttt{PTKVZ}, \textit{vor} in \textit{stellen Sie sich vor})
\item adjectival particle (German \texttt{PTKA}, \textit{am} in \textit{am besten}, \textit{zu} in \textit{zu groß})
\item existential \textit{there} in English (\texttt{EX})
\item measure word, quantifier (Chinese \texttt{DM})
\item genitive particle de in Chinese (\texttt{DE}) \zh{的} and \zh{得}
\item Chinese particles \zh{了} \translit{le} (perfect), \zh{著} \translit{zhe}, \zh{起} \translit{qǐ}, \zh{過} \translit{guò} (\texttt{Di})
\item Chinese particles \zh{了} \translit{le}, \zh{的} \translit{de}, \zh{來} \translit{lái} (\texttt{Ta})
\item Chinese particles \zh{而已} \translit{'éryǐ}, \zh{沒有} \translit{méiyǒu}, \zh{也罷} \translit{yěba}, \zh{沒有} \translit{méiyǒu}, \zh{好了} \translit{hǎole} (\texttt{Tb})
\item Chinese particles \zh{呢} \translit{ne}, \zh{吧} \translit{ba}, \zh{啊} \translit{'a}, \zh{囉} \translit{luō} (\texttt{Tc})
\item Chinese particles \zh{嗎} \translit{ma}, \zh{否} \translit{fǒu} (\texttt{Td})
\end{compactitem}

\subsection{Alternate Values}
\label{sec:valuearrays}

Some tagsets contain tags that encode two or more values of the same feature at the same time. For instance, the Czech PDT tags define 11 values for the third character of the tag, which denotes gender and animateness. Four are more or less independent values: \texttt{M} = ``masculine animate'', \texttt{I} = ``masculine inanimate'', \texttt{F} = ``feminine'' and \texttt{N} = ``neuter''. The rest are various combinations: \texttt{Y=(M|I)}, \texttt{T=(I|F)}, \texttt{W=(I|N)}, \texttt{H} and \texttt{Q=(F|N)}, \texttt{Z=(M|I|N)}, \texttt{X=(M|I|F|N)}. The obvious goal here is to make life easier for taggers because some word forms are systematically identical for two or more genders.

Interset does not define separate feature values for all combinations. However, it does allow for storing alternate values if necessary. Since the feature structure is implemented as a Perl hash, a reference to an array of values can be assigned to any feature in the decoder:

\begin{lstlisting}
elsif($gender eq "H") 
{ 
    $f{gender} = ["fem", "neut"]; 
}
\end{lstlisting}

At the first glance, such option poses a serious obstacle for encoder design. Before, the encoder was a nice sequence of \texttt{if} statements, merely saying ``if gender is \texttt{fem}, output character \texttt{F}''. Do we now need to check whether gender is array first? Even if we are writing driver for a tagset that never works with alternate values? Fortunately, no. Once again, the support library provides a procedure that can convert arrays to single values in all features except those that we acutally expect to contain arrays.

There is nonetheless one open question about alternate values. Interset cannot express permissible combinations of multiple features. In the Czech example above, \texttt{Q} actually means more than just ``feminine or neuter''. It means ``feminine singular or neuter plural''. Interset can store both genders and both numbers but by that it will also cover feminine plurals and neuter singulars.

\subsection{Joint Categories}
\label{sec:joint}

Every tagset assumes a certain tokenization of the tagged text. The tokenization guidelines may leave unsplit tokens that evolved historically from two words with separate categories. Examples include German \textit{zum = zu dem} ``to the'', Czech \textit{proň = pro něj} ``for him'' or \textit{žes = že jsi} ``that you have''. So in the German example, we have a token corresponding to two other tokens also occurring in the corpus, one tagged as preposition and the other as article.

Much more difficult is Arabic where orthographic rules dictate not to space-separate certain sequences of words. So for instance, the conjunction \ar{و} \translit{wa} ``and'', often thrown in at the sentence beginnings, is connected to the following word, as are prepositions. Tokenization cannot be finished before morphological analysis because word segmentation may have ambiguous solutions. Thus, in the following example, we'll end up with long tags \texttt{CONJ+PREP+NOUN\_PROP} and \texttt{NOUN+CASE\_DEF\_NOM}, respectively.

\lstset{language=XML}
\begin{lstlisting}[escapechar=\%]
<token_Arabic>%\ar{وبالفالوجة}%
  <voc>wabiAlfAlwjp</voc>
  <pos>wa/CONJ + bi/PREP +
       AlfAlwjp/NOUN_PROP</pos>
</token_Arabic>
<token_Arabic>%\ar{مثال}%
  <voc>mivAlu</voc>
  <pos>mivAl/NOUN + u/CASE_DEF_NOM</pos>
</token_Arabic>
\end{lstlisting}

Note that the first of the two examples corresponds to a sequence of three words (at least from the English perspective) while the second example describes just one noun (stem + suffix). The latter could be perfectly described in Interset; the former is the problem.

Interset currently covers Arabic tagset of the Prague Arabic Dependency Treebank \citep{padt}, which is already tokenized. For the more moderate examples from Czech and German, it pretends that one of the joint categories is a special feature of the other. Thus for \textit{zum}, Interset would note that it's a preposition with a special property \textit{attached article}. It would not express any relation to how independent articles are tagged. Alternatively, we could use the array approach described in \Sref{sec:valuearrays} and assign two values to the \texttt{pos} feature. Neither solution is optimal because both are far from universal. In theory any part of speech could combine with any other and there could be more than two concatenated tokens, each with its own features that should not be mixed all together. Future versions of Interset might introduce a concept of arrays of sequential features structures (to solve the Arabic puzzle above) and arrays of parallel feature structures (to cover the \textit{permissible feature combinations} discussed in \Sref{sec:valuearrays}). In the meantime, the conversion program using Interset has to split joint tags using its own means.

%\XXX Nějaká tabulka se statistikami?

\section{Conclusion}
\label{sec:conclusion}

We have described Interset, a reusable and universal method for tagset conversion via common set of features and their values. We have shown how tags from a source tagset are \textit{decoded} into this intermediate feature space, and how their \textit{encoding} into target tagset can automatically replace unavailable feature values by carefully selected defaults that minimize possible damage. We also briefly compared Interset to tagset standardization efforts and pointed out the differences in goals between standards and Interset. Finally, we presented numerous examples from real tagsets to illustrate the most difficult parts of tagset conversion. The solutions we proposed pursue the ultimate goal that information loss is minimized and similar information is encoded similarly, across tagsets and languages.

\section*{Acknowledgements}

%The research has been supported by the grant 
%MSM0021620838 (Czech Ministry of Education).

\begin{small}
\bibliography{paper}
\end{small}

\end{document}
