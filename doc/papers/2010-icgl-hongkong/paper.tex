% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode
% File acl-ijcnlp2009.tex
%
% Contact  jshin@csie.ncnu.edu.tw
%%
%% Based on the style files for EACL-2009 and IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl-ijcnlp2009}
\usepackage[	
   pdfdisplaydoctitle, breaklinks, colorlinks, linkcolor=black, citecolor=black, filecolor=black, urlcolor=black, 
   backref, hyperfootnotes]{hyperref} % backref a modre URL asi nakonec zrusime 
%\usepackage{times}
\usepackage{url}
\usepackage{amsmath}
\usepackage{color} %pro korektury
\usepackage{paralist} % for better itemize and enumerate

% a footer required for the first page (ICON but not ICGL)
\usepackage{fancyhdr}
\fancyhead{} % clear all header fields
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[C]{
%Proceedings of ICON-2009: 7th International Conference on Natural Language Processing, Macmillan Publishers, India. Also accessible from http://ltrc.iiit.ac.in/proceedings/ICON-2009
}

% xelatex
\usepackage{fontspec, xunicode, xltxtra}
\defaultfontfeatures{Mapping=tex-text}
\setmainfont{Times New Roman}
\setmonofont[Scale=MatchLowercase]{Luxi Mono}
\setmathsf{Lohit Hindi}%\XXX
%\newfontinstance\hi[Script=Devanagari]{Lohit Hindi}
\newfontinstance\hifont[Script=Devanagari]{Code2000}
\newfontinstance\bnfont[Script=Bengali]{Code2000}
\newfontinstance\tefont[Script=Telugu]{Code2000}
\newfontinstance\translitfont{Gentium}
\newcommand{\hi}[1]{{\hifont #1}}
\newcommand{\bn}[1]{{\bnfont #1}}
\newcommand{\te}[1]{{\tefont #1}}
\newcommand{\translit}[1]{{\translitfont \textit{(#1)}}}

% natbib
\usepackage{natbib}
\bibliographystyle{plainnat}
\bibpunct{(}{)}{;}{a}{,}{,}

% our defs
\def\perscite#1{\citet{#1}}  
\def\parcite#1{\citep{#1}} 
%ps: Did you mean \citep and \citet (in-parentheses and textual reference)? There is even more, see `texdoc natbib`.
\def\Sref#1{Section~\ref{#1}}
\def\Tref#1{Table~\ref{#1}}
\def\Fref#1{Figure~\ref{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}} % komentare (TODO)
\newcommand{\XXX}{\textcolor{red}{XXX }} % komentare (TODO)

\def\microsection#1{{\bf #1.}}



\title{Hard Problems of Tagset Conversion%
% Tohle nechat zakomentované, je to jen tahák, jak udělat acknowledgement grantu při nedostatku místa. Jinak ale mám momentálně na konci opravdovou sekci Acknowledgements.
%\thanks{ \hspace{.6em}The research has been supported by the grant 
%MSM0021620838 (Czech Ministry of Education).}
}

% Až to přestane být anonymní, tak také odkomentovat Acknowledgements a autoreference XXXX.
\author{%Daniel Zeman\\
%Univerzita Karlova v Praze, Ústav formální a aplikované lingvistiky\\
%Malostranské náměstí 25, CZ-11800, Praha, Czechia\\ 
%\texttt{zeman@ufal.mff.cuni.cz}
}

%\title{Instructions for ACL-IJCNLP 2009 Proceedings}
%
%\author{First Author\\
%  Affiliation / Address line 1\\
%  Affiliation / Address line 2\\
%  {\tt email@domain}  \And
%  Second Author\\
%  Affiliation / Address line 1\\
%  Affiliation / Address line 2\\
%  {\tt  email@domain}}

\date{}

\begin{document}
\maketitle
\thispagestyle{fancy}

\begin{abstract}
Part-of-speech or morphological tags are important means of annotation in a vast number of corpora. However, different sets of tags are used in different corpora, even for the same language. Tagset conversion is difficult, and solutions tend to be tailored to a particular pair of tagsets. We propose a universal approach that makes the conversion tools reusable. \XXX We also provide an indirect evaluation in the context of a parsing task.
\end{abstract}

\section{Introduction}
\label{sec:intro}

Most annotated corpora use various types of tags to encode additional information on words. In some cases this information is merely the part of speech (“noun”, “verb” etc.—hence the term \textit{part-of-speech} or \textit{POS tags}). In many cases, however, the string of characters comprising the tag is a compressed representation of a feature-value structure. Most of the features encoded this way are morphosyntactic (e.g. “gender = masculine”, “number = singular”), hence the term \textit{morphological tags}.

Unfortunately, it is very rare to see two corpora sharing a common set of tags. Language differences are only partially responsible—it is the corpus designers, their diverse views, theories and intended uses of the corpora, what matters most. Even two corpora of the same language may define two completely incompatible tagsets.

Such diversity proves disadvantageous for both human users and NLP software. A human user (linguist) typically wants to submit queries such as “show me all occurrences of a noun in plural, preceded by a preposition”. Tags however rarely contain statements like “number = plural” literally. That would be prohibitively space-consuming. Instead we have to know that e.g. the fourth character of the tag being “P” means “plural”. For instance, the tag \texttt{NNIS7-{}-{}-{}-{}-A-{}-{}-{}-}\footnote{This example is taken from the Prague Dependency Treebank \citep{pdt}.} may read as “part of speech = noun, detailed part of speech = common noun, gender = masculine inanimate, number = singular, case = 7th (instrumental), negativeness = affirmative”. To work with the corpus efficiently, a linguist either needs to interpret the tags using specialized software, or to memorize the particular tag scheme. Obviously, if the same linguist has to switch to a different corpus, he/she must memorize more schemes or replace the tag interpretation software.

Similarly, various NLP tools may depend on particular tagsets. While some tools indeed treat tags as atomic strings, others could exploit the tag structure to dig more information about the word—no matter whether they use the features in machine learning, or in human-designed rules. If the tagset changes, manual rules become useless and statistical models have to be retrained at least; even that may not be possible in case the training procedure works with selected subsets of the feature pool. Applicability of NLP software to multiple corpora is exactly the reason why one would want to convert tags from one tagset to another.

For many tagset pairs, designing the conversion procedure is not easy. On one hand, there are rare tagsets (e.g. MULTEXT-EAST, \citet{multext-east}) fitting at the same time languages as distant as Czech and Estonian; on the other hand, tagsets of two closely related languages (e.g. Danish and Swedish) or even two tagsets of the same language may differ substantially (for instance, the Mamba tagset of Swedish \citep{talbanken} contains detailed classification of auxiliary verbs and punctuation but lacks features like number, mood, tense etc.; this is in sharp contrast to another Swedish tagset, Parole \citep{parolesv}, which in turn is not compatible with the Danish Parole \citep{paroleda} tagset (the former classifies participles as verb forms, the latter as adjective forms; the former has separate tags for numerals, the latter classifies both cardinal and ordinal numbers as adjectives; etc.)

From the above said it follows that the typical tag conversion is an information-losing process. Though it is often desirable to perform it anyway and preserve as much information as possible. Creation of a conversion procedure between two tagsets requires hours of tedious work, consisting mostly of reading the tagging guidelines and translating them into a programming language. A universal description, to which all tagsets map, could make this process easier, and its results reusable. One attempt to find such description and deploy it in the conversion task is DZ Interset \citep{biblio:ZeReusableTagset2008}. In the present paper we discuss the development of the universal description and focus on selected hard problems that arise when comparing various existing tagsets.

The rest of the paper is organized as follows: In \XXX we describe Interset and how it works [\XXX including encoding algorithm] [\XXX including applications: Petr Pořízka, Saša Rosen, můj parsing]. In \XXX we describe our universal set of features. Then, \XXX lists decisions that are difficult w.r.t. universality, and propose solutions. Finally, we demonstrate the implications on real tagsets, and provide illustrative statistics.

\section{What Is Interset and What It Is Not}
\label{sec:whatisit}

\begin{compactitem}
\item it is not a standard like eagles, parole, gold ontology and that sort of crap
\item it is not a physical tagset (not intended to be used so - nemusim se ridit tim, co by radi lingvisti, aby jim to bylo bliz)
\item it looses information but it never adds information. If source tagset does not encode something, it simply won't be in Interset.
\item Specificaly, we do not retag words (say, we are converting from Brown to Penn, and hey, the word abc is tagged adverb in Brown and as conjunction in Penn... No! Unless we map all Brown adverbs on Interset conjunctions, which we probably don't want to, we will not change the tag of word abc. In fact, we NEVER look at the word the tag is assigned to. We work with the tag ONLY.
\end{compactitem}

\section{Conclusion}
\label{sec:conclusion}

\section*{Acknowledgements}

%The research has been supported by the grant 
%MSM0021620838 (Czech Ministry of Education).

\begin{small}
\bibliography{paper}
\end{small}

\end{document}
