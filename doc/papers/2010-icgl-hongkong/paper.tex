% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode
% File acl-ijcnlp2009.tex
%
% Contact  jshin@csie.ncnu.edu.tw
%%
%% Based on the style files for EACL-2009 and IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl-ijcnlp2009}
\usepackage[	
   pdfdisplaydoctitle, breaklinks, colorlinks, linkcolor=black, citecolor=black, filecolor=black, urlcolor=black, 
   backref, hyperfootnotes]{hyperref} % backref a modre URL asi nakonec zrusime 
%\usepackage{times}
\usepackage{url}
\usepackage{amsmath}
\usepackage{listings} % zdrojáky programů
\usepackage{color} %pro korektury
\usepackage{paralist} % for better itemize and enumerate

% a footer required for the first page (ICON but not ICGL)
\usepackage{fancyhdr}
\fancyhead{} % clear all header fields
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[C]{
%Proceedings of ICON-2009: 7th International Conference on Natural Language Processing, Macmillan Publishers, India. Also accessible from http://ltrc.iiit.ac.in/proceedings/ICON-2009
}

% xelatex
\usepackage{fontspec, xunicode, xltxtra}
\defaultfontfeatures{Mapping=tex-text}
\setmainfont{Times New Roman}
\setmonofont[Scale=MatchLowercase]{Luxi Mono}
\setmathsf{Lohit Hindi}%\XXX
%\newfontinstance\hi[Script=Devanagari]{Lohit Hindi}
\newfontinstance\arfont[Script=Arabic]{Code2000}
\newfontinstance\hifont[Script=Devanagari]{Code2000}
\newfontinstance\bnfont[Script=Bengali]{Code2000}
\newfontinstance\tefont[Script=Telugu]{Code2000}
\newfontinstance\zhfont{Code2000}
\newfontinstance\translitfont{Gentium}
\newcommand{\ar}[1]{{\arfont #1}}
\newcommand{\hi}[1]{{\hifont #1}}
\newcommand{\bn}[1]{{\bnfont #1}}
\newcommand{\te}[1]{{\tefont #1}}
\newcommand{\zh}[1]{{\zhfont #1}}
\newcommand{\translit}[1]{{\translitfont \textit{(#1)}}}

% natbib
\usepackage{natbib}
\bibliographystyle{plainnat}
\bibpunct{(}{)}{;}{a}{,}{,}

% our defs
\def\perscite#1{\citet{#1}}  
\def\parcite#1{\citep{#1}} 
%ps: Did you mean \citep and \citet (in-parentheses and textual reference)? There is even more, see `texdoc natbib`.
\def\Sref#1{Section~\ref{#1}}
\def\Tref#1{Table~\ref{#1}}
\def\Fref#1{Figure~\ref{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}} % komentare (TODO)
\newcommand{\XXX}{\textcolor{red}{XXX }} % komentare (TODO)

\def\microsection#1{{\bf #1.}}



% Tahák, jak udělat acknowledgement grantu při nedostatku místa.
\title{Hard Problems of Tagset Conversion\thanks{ \hspace{.6em}The research has been supported by the grant 
MSM0021620838 (Czech Ministry of Education).}
}

% Až to přestane být anonymní, tak také odkomentovat Acknowledgements a autoreference XXXX.
\author{Daniel Zeman\\
Univerzita Karlova v Praze, Ústav formální a aplikované lingvistiky\\
Malostranské náměstí 25, CZ-11800, Praha, Czechia\\ 
\texttt{zeman@ufal.mff.cuni.cz}
}

%\title{Instructions for ACL-IJCNLP 2009 Proceedings}
%
%\author{First Author\\
%  Affiliation / Address line 1\\
%  Affiliation / Address line 2\\
%  {\tt email@domain}  \And
%  Second Author\\
%  Affiliation / Address line 1\\
%  Affiliation / Address line 2\\
%  {\tt  email@domain}}

\date{}

\begin{document}
\maketitle
\thispagestyle{fancy}
\lstset{language=Perl}
\lstset{basicstyle=\ttfamily} % Pro zdrojový kód použít stejný font, jaký používám všude v \texttt{}.

\begin{abstract}
Part-of-speech or morphological tags are important means of annotation in a vast number of corpora. However, different sets of tags are used in different corpora, even for the same language. Tagset conversion is difficult, and solutions tend to be tailored to a particular pair of tagsets. We discuss Interset, a universal approach that makes the conversion tools reusable. While some morphosyntactic categories are clearly defined and easily ported from one tagset to another, there are also phenomena that are difficult to deal with because of overlapping concepts. In the present paper we focus on some of such problems, discuss their coverage in selected tagsets and propose solutions to unify the respective tagsets' approaches.
\end{abstract}

\section{Introduction}
\label{sec:intro}

Most annotated corpora use various types of tags to encode additional information on words. In some cases this information is merely the part of speech (“noun”, “verb” etc.—hence the term \textit{part-of-speech} or \textit{POS tags}). In many cases, however, the string of characters comprising the tag is a compressed representation of a feature-value structure. Most of the features encoded this way are morphosyntactic (e.g. “gender = masculine”, “number = singular”), hence the term \textit{morphological tags}.

Unfortunately, it is very rare to see two corpora sharing a common set of tags. Language differences are only partially responsible—it is the corpus designers, their diverse views, theories and intended uses of the corpora, what matters most. Even two corpora of the same language may define two completely incompatible tagsets.

Such diversity proves disadvantageous for both human users and NLP software. A human user (linguist) typically wants to submit queries such as “show me all occurrences of a noun in plural, preceded by a preposition”. Tags however rarely contain statements like “number = plural” literally. That would be prohibitively space-consuming. Instead we have to know that e.g. the fourth character of the tag being “P” means “plural”. For instance, the tag \texttt{NNIS7-{}-{}-{}-{}-A-{}-{}-{}-}\footnote{This example is taken from the Prague Dependency Treebank \citep{pdt}.} may read as “part of speech = noun, detailed part of speech = common noun, gender = masculine inanimate, number = singular, case = 7th (instrumental), negativeness = affirmative”. To work with the corpus efficiently, a linguist either needs to interpret the tags using specialized software, or to memorize the particular tag scheme. Obviously, if the same linguist has to switch to a different corpus, he/she must memorize more schemes or replace the tag interpretation software.

For many tagset pairs, designing the conversion procedure is not easy. On one hand, there are rare tagsets
% (e.g. MULTEXT-EAST, \citet{multext-east})
fitting at the same time languages as distant as Czech and Estonian; on the other hand, tagsets of two closely related languages (e.g. Danish and Swedish) or even two tagsets of the same language may differ substantially (for instance, the Mamba tagset of Swedish \citep{talbanken} contains detailed classification of auxiliary verbs and punctuation but lacks features like number, mood, tense etc.; this is in sharp contrast to another Swedish tagset, Parole \citep{parolesv}, which in turn is not compatible with the Danish Parole \citep{paroleda} tagset.
% (the former classifies participles as verb forms, the latter as adjective forms; the former has separate tags for numerals, the latter classifies both cardinal and ordinal numbers as adjectives; etc.)

From the above said it follows that the typical tag conversion is an information-losing process. Though it is often desirable to perform it anyway and preserve as much information as possible. Creation of a conversion procedure between two tagsets requires hours of tedious work, consisting mostly of reading the tagging guidelines and translating them into a programming language. A universal description, to which all tagsets map, could make this process easier, and its results reusable. One attempt to find such description and deploy it in the conversion task is DZ Interset \citep{biblio:ZeReusableTagset2008}. In the present paper we discuss the development of the universal description and focus on selected hard problems that arise when comparing various existing tagsets.

The rest of the paper is organized as follows: In \Sref{sec:interset} we describe Interset and how it works. Then, \Sref{sec:hard} lists decisions that are difficult w.r.t. universality, demonstrates them on real tagsets, and proposes solutions.

\section{Interset}
\label{sec:interset}

Interset is a universal set of features and their values. It shall be able to store all features that are usually encoded in tags. The role of this universal set is similar to the role of Interlingua in Interlingua-based machine translation \citep{interlingua} or the role of Unicode among character sets. The Interset serves as an intermediate step on the way from tagset A to tagset B. The interaction between the Interset and tagsets A and B, respectively, is described in \textit{tagset drivers}. Once the drivers have been implemented, we can do the two-way conversion A to B and B to A, plus the conversion to/from any other tagset that has been defined so far.

Besides abstract concept definitions, Interset also comprises some real software---supporting procedures that make adding new tagsets easier. Thanks to the encoding algorithm implemented in the support library, developers adding new tagsets need not (not necessarily) consider all features that are irrelevant to the tagset being added (but which may become relevant during conversion to a particular other tagset).

At the time of writing there are drivers for 20 tagsets of 10 languages, freely available on-line.\footnote{\url{https://wiki.ufal.ms.mff.cuni.cz/user:zeman:interset}}

%\XXX Vypustil jsem celou kapitolu o tom, jak fungují ovladače. Tím se ale ztratila informace o tom, že encoding řeší defaulty. Nevím, jestli se to tam nemá nějak stručně vrátit.

\subsection{A New Standard?}
\label{sec:notastandard}

\textbf{Interset is not a new annotation standard.} There have been attempts to standardize morphosyntactic tagging and it is not Interset's mission to compete with them. Instead, the goal is to cover as many existing tagsets as possible whether they conform to a standard or not. The set of Interset features and values could of course be compared to those defined in standards. There have been several European projects concerning tagset standardization. The EAGLES project \citep{eagles, LeechWilson1999} produced a set of recommendations for tagsets. Output of the LE-PAROLE project \citep{parole} was a multilingual corpus of 14 European languages, morphosyntactically annotated according to a common core PAROLE tagset, extended with a set of language specific features. Another multilingual corpus with common tagset is MULTEXT \citep{multext} for six European languages (en, fr, es, de, it, nl), and later its spin-off MULTEXT-EAST \citep{multext-east} for 12 languages (en, bg, cs, ee, hu, ro, sl, later also hr, lt, ru, sl-res);
%(English, Bulgarian, Czech, Estonian, Hungarian, Romanian, Slovene, later also Croatian, Lithuanian, Russian and Resian);
the tagsets used in MULTEXT corpora comply with EAGLES. Various EAGLES-compliant tagsets can be added to our system and their mutual similarity will probably make adding them all easier. Weakly related is also the Gold Ontology project \citep{gold-ontology} that defines various linguistic concepts, some of which serve as feature names and feature values in Interset. Similarly, morphosyntactic and other terms are included in IsoCat.\footnote{\url{http://www.isocat.org/}}

Interset has been used in cross-language parser adaptation \citep{ZemanResnik2008}, and in MorphCon, a GUI program that brings tag conversion to corpus users \citep{morphcon}. Currently, it is being deployed as a means of unified access to morphosyntactic annotation for the users of the parallel multilingual corpus Intercorp.\footnote{\url{http://www.korpus.cz/intercorp/?req=doc:uvod}}

\subsection{A New Tagset?}
\label{sec:notatagset}

\textbf{Interset is not primarily meant as a new \textit{physical} tagset for annotation.} Although it obviously could be used that way (possibly after compressing the feature values), it is better thought of as a set of concepts that physical tagsets map to.
%Design of physical tagsets is often guided by various needs such as conforming to linguistic tradition and terminology of the given language, minimizing errors of automatic disambiguation etc.
Physical tagsets often need to conform to linguistic tradition and terminology of the given language, minimize tagging errors etc.
In contrast, the most important design constraint for Interset is the portability of information from one tagset to the others.
If a feature value X is known in tagset A and unknown in B, and users of B are likely to tag the same words with feature value Y, then the Interset algorithms should replace X by Y.
%If a feature value X, encoded in tagset A, is not available in tagset B but it is still probable that users of tagset B would tag the same set of words with feature value Y, then it is desirable that the Interset algorithms are able to change X to Y, when converting from A to B.\footnote{See \citet{biblio:ZeReusableTagset2008} for details on the algorithm.}
%At the same time, converting to tagset C might require changing X to Z, converting to tagset D would keep X (because D has X, too) and converting to other tagsets would result in resetting X to empty value because there is no better choice available.

Conversion via Interset often looses information but never adds new information. Interset may define feature value X but it just won't be set unless the source tagset defines it, too. Specifically, the conversion procedure does not retag words. For instance, the source tagset may define one tag \texttt{IN} for both prepositions and subordinating conjunctions. The target tagset may have separate tags for each of those categories but Interset will not sort out the words tagged \texttt{IN}. In fact, the procedure \textit{never} looks at the word the tag is assigned to. It only works with the tag itself.

\section{The Hard Problems}
\label{sec:hard}

\subsection{Pronouns, Determiners, Wh-Adverbs}
\label{sec:pronouns}

Most languages and tagsets have personal pronouns, i.e. words like ``I'', ``you'', ``he''. Various interrogative and relative function words are often also considered pronouns. In addition, grammars of some languages distinguish \textit{determiners} while others prefer to categorize the same thing as a sort of pronouns. According to the definition of EAGLES, \textbf{pronoun} is a function word that \textit{replaces} a noun phrase, while \textbf{determiner} is a function word that \textit{modifies} a noun phrase. As a result, proper EAGLES-pronouns behave like nouns and determiners behave like adjectives. Note that possessive pronouns (i.e. ``my'', ``your''), also found in many languages, are personal possessive determiners in the sense of the EAGLES definition.

Because tagsets often disagree in what is pronoun, what is determiner etc., it is difficult to find a unifying approach. We decided to limit the number of the major parts of speech in order to minimize the cases where a word would end up with an empty part of speech. If there was a part of speech called \textit{determiner}, drivers of tagsets not having determiners would either have to check whether \texttt{\textbf{pos} = det} during encoding, or they would fall back into a residual word class. On the other hand, if we tag determiners as special cases of adjectives (which is what Interset does), such drivers will simply encode determiners as adjectives (which are much more common).

We also followed this solution with pronouns because of the following reasons:
\begin{compactitem}
\item Although pronouns are found in most tagsets, there is much controversy about the precise extent of that category.
\item Some tagsets allow for distinguishing between \textit{substantive} and \textit{attributive} pronouns. Assigning pronouns to nouns and adjectives respectively helps preserve that distinction.
\item Some of the features that distinguish pronouns from real nouns and adjectives (interrogativeness, for instance) are found with adverbs and numerals as well and thus it makes sense to separate them.
\end{compactitem}

Pronouns are recognized by nonempty value of the \texttt{prontype} feature.
%; default type is \texttt{prs}, which denotes personal pronouns under nouns, and possessive pronouns under adjectives. 
The drawback of this approach is that the encoding procedure of a driver that recognizes pronouns must define its own method of asking the question \textit{``Does the current feature structure correspond to a pronoun?''}

\subsection{Numerals}
\label{sec:numerals}

Numerals form an analogy to the pronoun-determiner problem. Most tagsets recognize cardinal numbers as a separate category. However, the rest is less obvious. Some tagsets recognize ordinal numbers while others classify them as adjectives because of their syntactic behavior.
%An extreme case is the Danish Parole tagset where all numbers including cardinals are adjectives; however, they form a distinguished subclass of adjectives and can thus be recognized.
%Tagsets of Czech and other Slavic languages define complex systems of numerals, according to traditional local grammars: besides cardinals and ordinals, there are separate tags for fractions (``one fifth''), multiplications (``five times''),\footnote{Note that in these languages such numerals can be expressed in one token, which justifies devising a tag for them.} adverbial ordinals (``for the first time''), various types of generic ordinals (``twofold'', ``four kinds of''), interrogative or relative numerals (``how many'', ``what'',\footnote{Here, the expected answer is ``first'', ``second'' etc. The ``what'' corresponds to different Slavic word than in e.g. ``What do you do for living?'' An example from Czech is \textit{kolikátý}.} ``how many times''), demonstrative numerals (``that many'', ``that many times''), indefinite numerals (``few'', ``much'') etc.
Some Slavic tagsets define complex systems of numerals, according to traditional local grammars: besides cardinals and ordinals, there are separate tags for fractions, multiplications, adverbial ordinals, generic ordinals, interrogative, relative, demonstrative or indefinite numerals.

For the sake of consistency, the solution should be parallel to that of pronouns. Cardinal numbers, as the most specific and most widely recognized category, should retain their independence. The rest will be split among nouns (fractions), adjectives (ordinals and some generics) and adverbs (multiplications and ordinal points in time). Non-empty \texttt{numtype} feature will distinguish them from real nouns, adjectives and adverbs. Parallelly, \texttt{prontype} could be set, too, for interrogative, demonstrative and indefinite numerals.

\subsection{Non-Finite Verb Forms}
\label{sec:participles}

Non-finite verb forms often constitute mixed categories from the syntactic point of view. The syntactic properties of participles overlap with adjectives. Similarly, gerunds resemble nouns and transgressives function as adverbs. At the same time however, they retain their verbal arguments.

Usually, these words are tagged as forms of verbs. However, there are exceptions. In the Swedish Parole tagset, participles are tagged as adjectives. Czech equivalent of gerunds is considered a deverbative noun.
%; Czech participles have long and short forms, the former being tagged as adjectives, the latter as verbs. Some tagsets could even delimit participles as a separate part of speech, without clearly marking their affinity to adjectives or verbs. 
The Interset guidelines prefer marking all three categories (participles, gerunds and transgressives) as verbs.\footnote{Note however that any guidelines are only to ensure unified approach to different presentations of the same information.
% It does not apply to information that simply is not there. 
If participles were tagged as \textit{normal} adjectives without sub-dividing adjectives into ``normal ones'' and participles, they would remain so in Interset and also in the target tagset.}

\subsection{Alternate Values}
\label{sec:valuearrays}

Some tagsets contain tags that encode two or more values of the same feature at the same time. For instance, the Czech PDT tags define 11 values for the third character of the tag, which denotes gender and animateness. Four are more or less independent values: \texttt{M} = ``masculine animate'', \texttt{I} = ``masculine inanimate'', \texttt{F} = ``feminine'' and \texttt{N} = ``neuter''. The rest are various combinations: \texttt{Y=(M|I)}, \texttt{T=(I|F)}, \texttt{W=(I|N)}, \texttt{H} and \texttt{Q=(F|N)}, \texttt{Z=(M|I|N)}, \texttt{X=(M|I|F|N)}. The obvious goal here is to make life easier for taggers because some word forms are systematically ambiguous.

Interset does not define separate feature values for all combinations. However, it does allow for storing alternate values if necessary:
%. Since the feature structure is implemented as a Perl hash, a reference to an array of values can be assigned to any feature in the decoder:

%elsif($gender eq "H") 
%{ 
\begin{lstlisting}
$f{gender} = ["fem", "neut"]; 
\end{lstlisting}
%}

At the first glance, such option poses a serious obstacle for encoder design. Before, the encoder was a nice sequence of \texttt{if} statements, merely saying ``if gender is \texttt{fem}, output character \texttt{F}''. Do we now need to check whether gender is array first? Even if we are writing driver for a tagset that never works with alternate values? Fortunately, no. Once again, the support library provides a procedure that can convert arrays to single values in all features except those that we acutally expect to contain arrays.

There is nonetheless one open question about alternate values. Interset cannot express permissible combinations of multiple features. In the Czech example above, \texttt{Q} actually means more than just ``feminine or neuter''. It means ``feminine singular or neuter plural''. Interset can store both genders and both numbers but by that it will also cover feminine plurals and neuter singulars.

\subsection{Joint Categories}
\label{sec:joint}

Every tagset assumes a certain tokenization of the tagged text. The tokenization guidelines may leave unsplit tokens that evolved historically from two words with separate categories. Examples include German \textit{zum = zu dem} ``to the'', Czech \textit{proň = pro něj} ``for him''.
% or \textit{žes = že jsi} ``that you have''. So in the German example, we have a token corresponding to two other tokens also occurring in the corpus, one tagged as preposition and the other as article.
We then have a token corresponding to two other tokens also occurring in the corpus, with different POS.

Much more difficult is Arabic where orthographic rules dictate not to space-separate certain sequences of words. So for instance, the conjunction \ar{و} \translit{wa} ``and'', often thrown in at the sentence beginnings, is connected to the following word, as are prepositions. Tokenization cannot be finished before morphological analysis because word segmentation may have ambiguous solutions. Thus, in the following example, we'll end up with long tags \texttt{CONJ+PREP+NOUN\_PROP} and \texttt{NOUN+CASE\_DEF\_NOM}, respectively.

\lstset{language=XML}
\begin{lstlisting}[escapechar=\%]
<token_Arabic>%\ar{وبالفالوجة}%
  <pos>wa/CONJ + bi/PREP +
       AlfAlwjp/NOUN_PROP</pos>
<token_Arabic>%\ar{مثال}%
  <pos>mivAl/NOUN + u/CASE_DEF_NOM</pos>
\end{lstlisting}
%  <voc>wabiAlfAlwjp</voc>
%</token_Arabic>
%  <voc>mivAlu</voc>
%</token_Arabic>

Note that the first of the two examples corresponds to a sequence of three words (at least from the English perspective) while the second example describes just one noun (stem + suffix). The latter could be perfectly described in Interset; the former is the problem.

%Interset currently covers Arabic tagset of the Prague Arabic Dependency Treebank \citep{padt}, which is already tokenized. For the more moderate examples from Czech and German, it pretends that one of the joint categories is a special feature of the other.
For the Czech and German examples above, Interset encodes one of the joint categories as a feature of the other.
Thus for \textit{zum}, Interset would note that it's a preposition with a special property \textit{attached article}. It would not express any relation to how independent articles are tagged. Alternatively, we could use the array approach described in \Sref{sec:valuearrays} and assign two values to the \texttt{pos} feature. Neither solution is optimal because both are far from universal. In theory any part of speech could combine with any other and there could be more than two concatenated tokens, each with its own features that should not be mixed all together.
%Future versions of Interset might introduce a concept of arrays of sequential features structures (to solve the Arabic puzzle above) and arrays of parallel feature structures (to cover the \textit{permissible feature combinations} discussed in \Sref{sec:valuearrays}). In the meantime, the conversion program using Interset has to split joint tags using its own means.

\section{Conclusion}
\label{sec:conclusion}

We have described Interset, a reusable and universal method for tagset conversion via common set of features and their values. We briefly compared Interset to tagset standardization efforts and pointed out the differences in goals between standards and Interset. Then we presented numerous examples from real tagsets to illustrate the most difficult parts of tagset conversion. The solutions we proposed pursue the ultimate goal that information loss is minimized and similar information is encoded similarly, across tagsets and languages.

% Šetříme místem, granty uvádíme v poznámce na první straně.
%\section*{Acknowledgements}

%The research has been supported by the grant 
%MSM0021620838 (Czech Ministry of Education).

\begin{small}
\bibliography{paper}
\end{small}

\end{document}
